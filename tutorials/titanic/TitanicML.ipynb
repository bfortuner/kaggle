{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to download the data from Kaggle using the kaggle-cli\n",
    "\n",
    "$ kg download -c titanic\n",
    "$ kg submit mypredictions.csv -c titanic -m \"My submission msg\"   #when we want to submit\n",
    "\n",
    "PassengerId -- A numerical id assigned to each passenger.\n",
    "Survived -- Whether the passenger survived (1), or didn't (0). We'll be making predictions for this column.\n",
    "Pclass -- The class the passenger was in -- first class (1), second class (2), or third class (3).\n",
    "Name -- the name of the passenger.\n",
    "Sex -- The gender of the passenger -- male or female.\n",
    "Age -- The age of the passenger. Fractional.\n",
    "SibSp -- The number of siblings and spouses the passenger had on board.\n",
    "Parch -- The number of parents and children the passenger had on board.\n",
    "Ticket -- The ticket number of the passenger.\n",
    "Fare -- How much the passenger paid for the ticker.\n",
    "Cabin -- Which cabin the passenger was in.\n",
    "Embarked -- Where the passenger boarded the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = \"data/\"\n",
    "\n",
    "orig_data_frame = pd.read_csv(DATA_DIR+'train.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = orig_data_frame.copy()\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add interesting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>FancyName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  FamilySize  FancyName  \n",
       "0      0         A/5 21171   7.2500   NaN        S           1          0  \n",
       "1      0          PC 17599  71.2833   C85        C           1          0  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S           0          0  \n",
       "3      0            113803  53.1000  C123        S           1          0  \n",
       "4      0            373450   8.0500   NaN        S           0          0  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "df['FancyName'] = np.where(\n",
    "        ((df.Name.str.contains(\"Master.\")) \n",
    "        | (df.Name.str.contains(\"Rev.\")) \n",
    "        | (df.Name.str.contains(\"Dr.\"))\n",
    "        | (df.Name.str.contains(\"Dr.\")) \n",
    "        | (df.Name.str.contains(\"Sir.\"))),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Strings To Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>FancyName</th>\n",
       "      <th>EmbarkedCode</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  FamilySize  FancyName  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S           1          0   \n",
       "1      0          PC 17599  71.2833   C85        C           1          0   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S           0          0   \n",
       "3      0            113803  53.1000  C123        S           1          0   \n",
       "4      0            373450   8.0500   NaN        S           0          0   \n",
       "\n",
       "   EmbarkedCode  Gender  \n",
       "0           0.0       0  \n",
       "1           1.0       1  \n",
       "2           0.0       1  \n",
       "3           0.0       1  \n",
       "4           0.0       0  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Embarked'].unique()\n",
    "df['EmbarkedCode'] = df['Embarked'].map( {'S':0,'C':1,'Q':2} ) \n",
    "df['Gender'] = df['Sex'].map( {'male':0,'female':1} )\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "Survived          0\n",
       "Pclass            0\n",
       "Name              0\n",
       "Sex               0\n",
       "Age               0\n",
       "SibSp             0\n",
       "Parch             0\n",
       "Ticket            0\n",
       "Fare              0\n",
       "Cabin           687\n",
       "Embarked          2\n",
       "FamilySize        0\n",
       "FancyName         0\n",
       "EmbarkedCode      0\n",
       "Gender            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looks like Age and Embarked have Nulls\n",
    "df.isnull().sum()\n",
    "\n",
    "#Set missing Embarked to most common location\n",
    "df.groupby('EmbarkedCode').PassengerId.count()\n",
    "df = df.fillna(value={\"EmbarkedCode\":0})\n",
    "\n",
    "\n",
    "female_stats = df[(df.Sex==\"female\") & (df.Age.notnull())].groupby(['Sex','Pclass']).Age.median()\n",
    "male_stats = df[(df.Sex==\"male\") & (df.Age.notnull())].groupby(['Sex','Pclass']).Age.median()\n",
    "female_stats, male_stats\n",
    "\n",
    "for i in xrange(df.Pclass.nunique()):\n",
    "    df.loc[(df.Age.isnull()) & (df.Sex==\"female\") & (df.Pclass==i+1),'Age'] = female_stats[i]\n",
    "    \n",
    "for i in xrange(df.Pclass.nunique()):\n",
    "    df.loc[(df.Age.isnull()) & (df.Sex==\"male\") & (df.Pclass==i+1),'Age'] = female_stats[i]\n",
    "    \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove columns we don't need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>FancyName</th>\n",
       "      <th>EmbarkedCode</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  FamilySize  FancyName  \\\n",
       "0         0       3  22.0      1      0   7.2500           1          0   \n",
       "1         1       1  38.0      1      0  71.2833           1          0   \n",
       "2         1       3  26.0      0      0   7.9250           0          0   \n",
       "3         1       1  35.0      1      0  53.1000           1          0   \n",
       "4         0       3  35.0      0      0   8.0500           0          0   \n",
       "\n",
       "   EmbarkedCode  Gender  \n",
       "0           0.0       0  \n",
       "1           1.0       1  \n",
       "2           0.0       1  \n",
       "3           0.0       1  \n",
       "4           0.0       0  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = df.copy()\n",
    "df.columns\n",
    "\n",
    "df = df.drop('Ticket',1)\n",
    "df = df.drop('Cabin',1)\n",
    "df = df.drop('Name',1)\n",
    "df = df.drop('Embarked',1)\n",
    "df = df.drop('Sex',1)\n",
    "df = df.drop('PassengerId',1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived          int64\n",
       "Pclass            int64\n",
       "Age             float64\n",
       "SibSp             int64\n",
       "Parch             int64\n",
       "Fare            float64\n",
       "FamilySize        int64\n",
       "FancyName         int64\n",
       "EmbarkedCode    float64\n",
       "Gender            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_count = len(df.columns)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.copy()\n",
    "df.dtypes\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].astype(np.float)\n",
    "    \n",
    "df.dtypes\n",
    "df.EmbarkedCode.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bin fare types or age ranges? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0.        ,   3.        ,  22.        , ...,   7.25      ,\n",
       "           0.        ,   0.        ],\n",
       "        [  1.        ,   1.        ,  38.        , ...,  71.28330231,\n",
       "           1.        ,   1.        ],\n",
       "        [  1.        ,   3.        ,  26.        , ...,   7.92500019,\n",
       "           0.        ,   1.        ],\n",
       "        ..., \n",
       "        [  0.        ,   3.        ,  21.5       , ...,  23.45000076,\n",
       "           0.        ,   1.        ],\n",
       "        [  1.        ,   1.        ,  26.        , ...,  30.        ,\n",
       "           1.        ,   0.        ],\n",
       "        [  0.        ,   3.        ,  32.        , ...,   7.75      ,\n",
       "           2.        ,   0.        ]], dtype=float32),\n",
       " array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "        105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "        118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "        144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
       "        157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
       "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
       "        209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
       "        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
       "        235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
       "        248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n",
       "        261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273,\n",
       "        274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n",
       "        287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299,\n",
       "        300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n",
       "        313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
       "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
       "        339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
       "        352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
       "        365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
       "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n",
       "        391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n",
       "        404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
       "        417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n",
       "        430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
       "        443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n",
       "        456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n",
       "        469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
       "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
       "        495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507,\n",
       "        508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520,\n",
       "        521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533,\n",
       "        534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546,\n",
       "        547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559,\n",
       "        560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572,\n",
       "        573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585,\n",
       "        586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598,\n",
       "        599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611,\n",
       "        612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624,\n",
       "        625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637,\n",
       "        638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650,\n",
       "        651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663,\n",
       "        664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676,\n",
       "        677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689,\n",
       "        690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702,\n",
       "        703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715,\n",
       "        716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728,\n",
       "        729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741,\n",
       "        742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754,\n",
       "        755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767,\n",
       "        768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780,\n",
       "        781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793,\n",
       "        794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806,\n",
       "        807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819,\n",
       "        820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832,\n",
       "        833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845,\n",
       "        846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858,\n",
       "        859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871,\n",
       "        872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884,\n",
       "        885, 886, 887, 888, 889, 890, 891]))"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = \"data/\"\n",
    "\n",
    "def prepare_data(filename):\n",
    "    df = pd.read_csv(DATA_DIR+filename, header=0)\n",
    "\n",
    "    #Add interesting columns -- these did not help\n",
    "    '''\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "    df['FancyName'] = np.where(\n",
    "            ((df.Name.str.contains(\"Master.\")) \n",
    "            | (df.Name.str.contains(\"Rev.\")) \n",
    "            | (df.Name.str.contains(\"Dr.\"))\n",
    "            | (df.Name.str.contains(\"Dr.\")) \n",
    "            | (df.Name.str.contains(\"Sir.\"))),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    '''\n",
    "    #Map strings to numbers\n",
    "    df['EmbarkedCode'] = df['Embarked'].map( {'S':0,'C':1,'Q':2} ) \n",
    "    df['Gender'] = df['Sex'].map( {'male':0,'female':1} )\n",
    "    \n",
    "    #Set missing Embarked + Fare\n",
    "    df = df.fillna(value={\"EmbarkedCode\":df.EmbarkedCode.mode()[0]})\n",
    "    df = df.fillna(value={\"Fare\":df.Fare.mean()})\n",
    "\n",
    "    #Set missing Age based on Sex and Pclass\n",
    "    female_stats = df[(df.Sex==\"female\") & (df.Age.notnull())].groupby(['Sex','Pclass']).Age.median()\n",
    "    for i in xrange(df.Pclass.nunique()):\n",
    "        df.loc[(df.Age.isnull()) & (df.Sex==\"female\") & (df.Pclass==i+1),'Age'] = female_stats[i]\n",
    "    male_stats = df[(df.Sex==\"male\") & (df.Age.notnull())].groupby(['Sex','Pclass']).Age.median()\n",
    "    for i in xrange(df.Pclass.nunique()):\n",
    "        df.loc[(df.Age.isnull()) & (df.Sex==\"male\") & (df.Pclass==i+1),'Age'] = female_stats[i]\n",
    "    \n",
    "    #Drop unnessary columns\n",
    "    passenger_ids = df['PassengerId'].values\n",
    "    df = df.drop(['Ticket', 'Cabin', 'Name', 'Embarked', 'Sex', 'PassengerId'], axis=1) \n",
    "\n",
    "    #Convert everything to floats\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].astype(np.float32)\n",
    "    return df.values,passenger_ids\n",
    "    \n",
    "trained_data_matrix = prepare_data(\"train.csv\")\n",
    "trained_data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Survived must be 1st column in training set!\n",
    "train_data, train_pids = prepare_data(\"train.csv\")\n",
    "test_data, test_pids = prepare_data(\"test.csv\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "# Create the random forest object which will include all the parameters\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# Fit the training data to the Survived labels and create the decision trees\n",
    "forest = forest.fit(train_data[0::,1::],train_data[0::,0])\n",
    "\n",
    "# Take the same decision trees and run it on the test data\n",
    "predictions = forest.predict(test_data).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create predictions file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame({\"PassengerId\":test_pids,\"Survived\":predictions})\n",
    "predictions_df.head()\n",
    "predictions_df.to_csv(DATA_DIR+\"forestpredictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
